#!/bin/bash
if [ -z "$my_dir" ]; then my_dir="$(dirname "$0")"; fi
. "$my_dir/common"

scaleio_cluster_rids=(`relation-ids scaleio-cluster`)
if [[ -z ${scaleio_cluster_rids[*]+x} ]]; then exit 0; fi
scaleio_cluster_rid=${scaleio_cluster_rids[0]}
required_mode=`config-get cluster-mode`
current_mode=`leader-get cluster_mode`
eval `leader-get cluster_nodes`
eval `leader-get ordered_nodes`
declare -A present_nodes=()
declare -A leaving_nodes=()
declare -A ready_nodes=()
declare -A required_count
declare -A current_count
declare -A leaving_count=([tb]=0 [manager]=0)
declare -A present_count=([tb]=0 [manager]=0 [none]=0)
required_count[tb]=$(( (required_mode-1)/2 ))
required_count[manager]=$(( (required_mode+1)/2))
current_count[tb]=$(( (current_mode-1)/2 ))
current_count[manager]=$(( (current_mode+1)/2))

# Head function here - can be called to adjust current cluster according to current and requested cluster-mode

function adjust-cluster {
    if [[ -z ${scaleio_cluster_rid+x} ]]; then exit 0; fi

    # Fill up the info about existing and removed nodes
    retrieve-cluster-info

    # Update cluster IPs because ScaleIO doesn't work sometimes with IPs of removed cluster MDMs in the list
    update-cluster-ips
    MY_MDMS=`leader-get mdm_management_ips`

    # Adjust or restore cluster
    if (( required_mode < current_mode )); then
        reduce-cluster
    elif (( required_mode == current_mode && (leaving_count[manager] > 0 || leaving_count[tb] > 0) )); then
        restore-cluster
    elif (( required_mode > current_mode )); then
        grow-cluster
    fi
}

# Queries all existing nodes participating in relation and compiles hashes with present and
# leaving nodes and their roles

function retrieve-cluster-info {
    # Looking up present nodes and recording their roles in present_nodes
    local nodes=(`relation-list -r $scaleio_cluster_rid` $JUJU_UNIT_NAME)
    for node in ${nodes[*]}; do
        local role=`relation-get -r $scaleio_cluster_rid role $node`
        # If some role doesn't exist exit and wait for the node to get initialized
        if [ -z ${role} ]; then exit; fi
        present_nodes[$node]=$role
        present_count[$role]=$(( present_count[$role]+1 ))
    done

    # Looking for absent nodes and recording their roles in leaving_nodes
    for node in ${!cluster_nodes[*]}; do
        if [ -z "${present_nodes[$node]+x}" ]; then
            local role=${cluster_nodes[$node]}
            leaving_nodes[$node]=$role
            leaving_count[$role]=$(( leaving_count[$role]+1 ))
        fi
    done
}

# Checks sufficiency of nodes of required roles after previous ordering

function order-status {
    declare -A additional_nodes_count=([manager]=$1 [tb]=$2)

    for node in ${!present_nodes[*]}; do
        if [ -n "${cluster_nodes[$node]+x}" ]; then continue; fi
        local role=${present_nodes[$node]}
        if (( additional_nodes_count[$role]-- > 0)); then
            ready_nodes[$node]=$role
        fi
    done
    # Check if requirements are satisfied
    if (( additional_nodes_count[manager] > 0 || additional_nodes_count[tb] > 0 )); then
        juju-log "ScaleIO MDM cluster, not enough required roles exist - need to order more"
        ready_nodes=()
    fi
}

function check-and-set-role {
    # Refresh ordered_nodes for the case when it is called from order-nodes for the leader
    eval `leader-get ordered_nodes`
    # Check if this node is ordered to change role
    if [ -n "${ordered_nodes[*]+x}" ] && [ -n "${ordered_nodes[$JUJU_UNIT_NAME]+x}" ]; then
        # This node is ordered to change role
        ordered_role=${ordered_nodes["$JUJU_UNIT_NAME"]}
        if [[ "${present_nodes[$JUJU_UNIT_NAME]+x}" != "$ordered_role" ]]; then
            if [[ $ordered_role == manager ]]; then
                is_manager=1
                relation-set -r $scaleio_cluster_rid management_ip=$MY_MANAGEMENT_IP
            else
                is_manager=0
            fi
            # Remove it from list of standbies first, just in case error occurred in previous cluster adjustments
            cluster-cmd "scaleio::mdm { 'remove from cluster': name=>'$MY_NAME', ensure=>'absent' }"
            server-cmd "class { 'scaleio::mdm_server': is_manager=>$is_manager }"
            relation-set -r $scaleio_cluster_rid role=$ordered_role
            juju-log "ScaleIO MDM $MY_NAME changed role to $ordered_role"
        fi
        status-set waiting "Waiting to become cluster member with a role ${ordered_role}"
   fi
}

# Orders spare nodes to assume required roles to become cluster members if not enough yet

function order-nodes {
    local additional_manager_count=$1
    local additional_tb_count=$2

    # Check if enough nodes of required roles exist
    order-status $additional_manager_count $additional_tb_count
    if [ -n "${ready_nodes[*]+x}" ] || [ -n "${ordered_nodes[*]+x}" ]; then return 0; fi

    # Order required roles
    declare -A ordered_nodes=()
    for node in ${!present_nodes[*]}; do
        if [ -n "${cluster_nodes[$node]+x}" ]; then continue; fi
        if (( additional_manager_count > 0 )); then
            ordered_nodes[$node]=manager
            additional_manager_count=$(( additional_manager_count-1 ))
        elif (( additional_tb_count > 0 )); then
            ordered_nodes[$node]=tb
            additional_tb_count=$(( additional_tb_count-1 ))
        fi
    done

    # Check if enough spares exists
    if (( additional_manager_count > 0 || additional_tb_count > 0 )); then
        juju-log "Not enough spare nodes exist - requested mode: $required_mode, current mode: $current_mode"
    else
        leader-set ordered_nodes="`declare -p ordered_nodes`"
        check-and-set-role
        # In case this is the leader which just acquired its role according to ordered_nodes in the call above
        # we need to call adjust-cluster now because there won't be any other relation or leadership hooks called
        adjust-cluster
    fi
}

# Checks possibility and reduces the cluster to required mode

function reduce-cluster {
    juju-log "Trying to reduce cluster from $current_mode to $required_mode"

    mode_change=$(( (current_mode - required_mode) / 2 ))

    local reducing_msg=''
    local manager_change=$(( mode_change - leaving_count[manager] ))
    local tb_change=$(( mode_change - leaving_count[tb] ))
    if (( required_mode == 1 )); then
        # Resizing from 5 or 3 to 1 can be done half-nicely, we should wait for managers to depart and then remove the tiebreakers and switch to 1
        # Removing of all MDMs except one manager at the moment kills the cluster so we have to resort to having one tiebreaker left at least
        # In order to determine which manager will stay we need to wait for the rest of them to leave
        if (( leaving_count[manager] < mode_change && leaving_count[tb] == 0 )); then
                reducing_msg="waiting for ${manager_change} MDM managers to leave"
            # All cases below are invalid for cluster reduction to 1
        elif (( current_mode == 5 && leaving_count[manager] == 1 && leaving_count[tb] == 1 )); then
            reducing_msg="cluster can't be reduced to 1 with 1 manager and 1 tiebreaker gone, either restore it to 5 or switch to 3-node mode"
        elif (( current_mode == 5 && leaving_count[manager] == 0 && leaving_count[tb] == 1 )); then
            reducing_msg="cluster can't be reduced to 1 with 1 tiebreaker gone, either restore it to 5 or switch to 3-node mode and remove 1 manager"           
        elif (( leaving_count[manager] == 0 && leaving_count[tb] > 0 )); then
            reducing_msg="cluster can't be reduced to 1 with ${leaving_count[tb]} tiebreaker(s) removed, please restore it to ${current_mode}-node mode"
        fi
    elif (( leaving_count[tb] + leaving_count[manager] < 2 )); then
        # Resizing from 5 to 3 can be done nicely, waiting until specific nodes are removed explicitly
        reducing_msg="waiting for ${manager_change} MDM manager(s) and ${tb_change} MDM tiebreaker(s) to leave"
    # All cases below are invalid for cluster reduction to 3
    elif (( leaving_count[tb] == 2 )); then
        reducing_msg="cluster can't be reduced to 3 with 2 tiebreakers gone, please restore it to 5-node mode"
    elif (( leaving_count[manager] == 2 )); then
        reducing_msg="cluster can't be reduced to 3 with 2 managers gone, please restore it to 5-node mode or switch to 1-node mode"
    fi

    # Letting cluster nodes know that they need to block,
    # blocking current leader and revealing its status in case it's cluster member
    if [ -n "${reducing_msg}" ]; then
        juju-log "Reducing cluster from ${current_mode} to ${required_mode} is not done - $reducing_msg"
        leader-set reducing_cluster="$reducing_msg"
        if [ -n "${cluster_nodes[$JUJU_UNIT_NAME]+x}" ]; then
            status-set blocked "Cluster member with a role ${cluster_nodes[$JUJU_UNIT_NAME]} - $reducing_msg"
        fi
        return 0
    fi

    juju-log "Preparing to reduce cluster"

    # Prepare leaving nodes for removing
    declare -A mode_change_count=([manager]=$mode_change [tb]=$mode_change)
    to_remove=()
    declare -A remove_str
    for node in ${!leaving_nodes[*]} ${!cluster_nodes[*]}; do
        local role=${cluster_nodes[$node]}
        local name=`convert-name $node`
        if [[ remove_str[$role] == *"$name,"* ]] || (( mode_change_count[$role]-- <= 0 )); then continue; fi
        to_remove+=($node)
        remove_str[$role]+="$name,"
    done

    # Issue the cluster command for reducing
    juju-log "ScaleIO cluster is being reduced to $required_mode - managers: ${remove_str[manager]}, tbs: ${remove_str[tb]}"
    cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${remove_str[manager]}', tb_names=>'${remove_str[tb]}', ensure=>'absent' }"
    for node in ${to_remove[*]}; do
        local name=`convert-name $node`
        cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ensure=>'absent' }"
        unset cluster_nodes[$node]
    done
    juju-log "ScaleIO cluster is successfully reduced to $required_mode"

    status-set active
    update-cluster-ips
    leader-set cluster_nodes="`declare -p cluster_nodes`" cluster_mode=$required_mode reducing_cluster=
}

# Checks and restores degraded cluster if enough spare nodes exist
# Orders required roles and waits until ready_nodes are delivered

function restore-cluster {
    # Restore the Cluster

    order-nodes ${leaving_count[manager]} ${leaving_count[tb]}
    if [ -z "${ready_nodes[*]+x}" ]; then return 0; fi

    # Ordered roles delivered, restoring the Cluster

    # Prepare replacement nodes for adding
    declare -A adding_count=([manager]=0 [tb]=0)
    declare -A add_str=([manager]='' [tb]='')
    for node in ${!ready_nodes[*]}; do
        local name=`convert-name $node`
        local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
        local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
        local role=${ready_nodes[$node]}
        cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
        add_str[$role]+="$name,"
        adding_count[$role]=$(( adding_count[$role]+1 ))
        cluster_nodes[$node]=$role
    done

    # Prepare leaving nodes for removing, not exceeding the number of adding nodes
    declare -A remove_str=([manager]='' [tb]='')
    to_remove=()
    for node in ${!leaving_nodes[*]}; do
        local role=${cluster_nodes[$node]}
        if (( adding_count[$role]-- <= 0 )); then continue; fi
        local name=`convert-name $node`
        remove_str[$role]+="$name,"
        to_remove+=($node)
        unset cluster_nodes[$node]
    done

    # Issue the cluster command for growing
    juju-log "ScaleIO cluster is being restored to $required_mode with adding managers ${add_str[manager]} " \
        "tbs ${add_str[tb]} removing managers ${remove_str[manager]} tbs ${remove_str[tb]}"
    cluster-cmd "scaleio::cluster {'cluster': slave_names=>'${add_str[manager]}', tb_names=>'${add_str[tb]}', slave_names_to_replace=>'${remove_str[manager]}', tb_names_to_replace=>'${remove_str[tb]}' }"
    for node in ${to_remove[*]}; do
        local name=`convert-name $node`
        cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ensure=>'absent' }"
        unset cluster_nodes[$node]
    done
    juju-log "ScaleIO cluster is successfully restored to $required_mode"

    status-set active
    update-cluster-ips
    leader-set ordered_nodes=
    leader-set cluster_nodes="`declare -p cluster_nodes`" reducing_cluster=
}

# Grows cluster if mode change is requested and enough spare nodes exist
# Orders required roles and waits until ready_nodes are delivered

function grow-cluster {
    # Grow the Cluster
    mode_change=$(( (required_mode - current_mode) / 2 ))

    order-nodes $mode_change $mode_change
    if [ -z "${ready_nodes[*]+x}" ]; then return 0; fi

    # Prepare replacement nodes for adding
    declare -A add_str=([manager]='' [tb]='')
    for node in ${!ready_nodes[*]}; do
        local name=`convert-name $node`
        local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
        local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
        local role=${ready_nodes[$node]}
        cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
        add_str[$role]+="$name,"
        cluster_nodes[$node]=$role
    done

    # Issue the cluster command for growing
    juju-log "ScaleIO cluster is being grown to $required_mode - managers: ${add_str[manager]}, tbs: ${add_str[tb]}"
    cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${add_str[manager]}', tb_names=>'${add_str[tb]}' }"
    juju-log "ScaleIO cluster is successfully grown to $required_mode"

    update-cluster-ips
    leader-set ordered_nodes=
    leader-set cluster_nodes="`declare -p cluster_nodes`" cluster_mode=$required_mode
    status-set active
}

# Updates cluster internal and management ips in leader settings

function update-cluster-ips {
    # The function should be called by leader only

    nodes=($(relation-list -r $scaleio_cluster_rid))
    # JUJU doesn't return this current unit in the list so we have to add it here explicitely
    nodes+=($JUJU_UNIT_NAME)

    local internal_ips=''
    local management_ips=''
    for node in ${!cluster_nodes[*]}; do
        if [[ "${nodes[*]}" != *$node* ]]; then continue; fi
        local role=${cluster_nodes[$node]}
        if [[ $role == tb ]]; then continue; fi
        local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
        local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
        internal_ips+="$internal_ip,"
        management_ips+="$management_ip,"
    done
    leader-set mdm_internal_ips=$internal_ips mdm_management_ips=$management_ips
    relation-set-all
}
