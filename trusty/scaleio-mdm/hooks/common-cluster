#!/bin/bash
if [ -z "$my_dir" ]; then my_dir="$(dirname "$0")"; fi
. "$my_dir/common"

scaleio_cluster_rids=(`relation-ids scaleio-cluster`)
scaleio_cluster_rid=${scaleio_cluster_rids[0]}
required_mode=`config-get cluster-mode`
current_mode=`leader-get cluster_mode`
eval `leader-get cluster_nodes`
eval `leader-get ordered_nodes`
declare -A present_nodes=()
declare -A leaving_nodes=()
declare -A required_count
declare -A current_count
declare -A leaving_count=([tb]=0 [slave]=0)
declare -A present_count=([tb]=0 [slave]=0)
required_count[tb]=$(( (required_mode-1)/2 ))
required_count[slave]=$(( (required_mode+1)/2))
current_count[tb]=$(( (current_mode-1)/2 ))
current_count[slave]=$(( (current_mode+1)/2))

function retrieve-cluster-info {
	# The function should be called in a scope of scaleio-cluster-relation-* hooks only

	# Looking up present nodes and recording their roles in present_nodes
	local nodes=`relation-list -r $scaleio_cluster_rid`
  	for node in $nodes; do
  		# TODO: Most probably the check below isn't required
  		if [ $JUJU_HOOK_NAME == 'scaleio-cluster-relation-departed' ] && [ $JUJU_REMOTE_UNIT == $node ]; then continue; fi
  		local role=`relation-get -r $scaleio_cluster_rid role $node`
		present_nodes[$node]=$role
		present_count[$role]=$(( present_count[$role]+1 ))
    done

	# Looking for absent nodes and recording their roles in leaving_nodes
	for node in ${!cluster_nodes[*]}; do
		if [ -z "${present_nodes[$node]+x}" ]; then
			local role=${cluster_nodes[$node]}
			leaving_nodes[$node]=$role
			leaving_count[$role]=$(( leaving_count[$role]+1 ))
		fi
	done
} 	

function adjust-cluster {
	# The function should be called in a scope of scaleio-cluster-relation-* hooks only

	retrieve-cluster-info

	# Adjust or restore cluster
	if (( required_mode < current_mode )); then
		reduce-cluster
	elif (( required_mode == current_mode && (leaving_count[slave] > 0 || leaving_count[tb] > 0) )); then
		restore-cluster
	elif (( required_mode > current_mode )); then
		grow-cluster
	fi
}

function order-nodes {
	# Check if we have enough ready nodes of required roles. Order and return if not
	local absent_slave_count=$1
	local absent_tb_count=$2

	# Already ordered, leave and wait while they set up
	if [ -n "${ordered_nodes+x}" ]; then return 1; fi

	# Order required roles
	declare -A ordered_nodes
	for node in ${!present_nodes[*]}; do
		if [ -n "${cluster_nodes[$node]+x}" ]; then continue; fi
		if (( absent_slave_count > 0 )); then
			ordered_nodes[$node]=slave
			absent_slave_count=$(( absent_slave_count-1 ))
		elif (( absent_tb_count > 0 )); then
			ordered_nodes[$node]=tb
			absent_tb_count=$(( absent_tb_count-1 ))
		fi
	done
		
	# Check if enough spares exists
	if (( absent_slave_count > 0 || absent_tb_count > 0 )); then
		juju-log "Not enough spare nodes exist - requested mode: $required_mode, current mode: $current_mode"
	else
		leader-set ordered_nodes="`declare -p ordered_nodes`"
	fi
}

function reduce-cluster {
	# Reduces the Cluster

	mode_change=$(( (current_mode - required_mode) / 2 ))
	
	# Resizing from 5 or 3 to 1 can be done half-nicely, we should wait for slaves to depart and then remove the tiebreakers and switch to 1
	# Removing of all MDMs except one manager at the moment kills the cluster so we have to resort to having one tiebreaker left at least
	# In order to determine which manager will stay we need to wait for the rest of them to leave
	if (( required_mode == 1 && leaving_count[slave] < mode_change )); then
		juju-log "Reducing cluster to 1 is not done - waiting for slaves to depart first"
		return 0
	fi

	# Resizing from 5 to 3 can be done nicely, waiting until specific nodes are removed explicitly
	if (( required_mode == 3 && (leaving_count[tb] == 0 || leaving_count[slave] == 0) )); then
		juju-log "Reducing cluster from 5 to 3 is not done - waiting for more nodes to depart first"
		return 0
	fi

	# Prepare leaving nodes for removing
	declare -A mode_change_count=([slave]=$mode_change [tb]=$mode_change)
	to_remove=()
	declare -A remove_str
	for node in ${!leaving_nodes[*]} ${!cluster_nodes[*]}; do
		local role=${cluster_nodes[$node]}
		local name=`convert-name $node`
		if [[ remove_str[$role] == *"$name,"* ]] || (( mode_change_count[$role]-- <= 0 )); then continue; fi
		to_remove+=($node)
		remove_str[$role]+="$name,"
	done
	
	# Issue the cluster command for reducing
	juju-log "ScaleIO cluster is being reduced to $required_mode - slaves: ${remove_str[slave]}, tbs: ${remove_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${remove_str[slave]}', tb_names=>'${remove_str[tb]}', ensure=>'absent' }"
	for node in ${to_remove[*]}; do
		local name=`convert-name $node`
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ensure=>'absent' }"
		unset cluster_nodes[$node]
	done
	juju-log "ScaleIO cluster is successfully reduced to $required_mode"

	update-cluster-ips
	leader-set cluster_nodes="`declare -p cluster_nodes`"
}

function restore-cluster {
	# Restore the Cluster

	if [[ `order-nodes leaving_count[slave] leaving_count[tb]` == 1 ]]; then
		# Ordered required roles, leaving for now
		return 0
	fi

	# Ordered roles delivered, restoring the Cluster
	
	# Prepare replacement nodes for adding
	declare -A adding_count=([slave]=0 [tb]=0)
	declare -A add_str=([slave]='' [tb]='')
	for node in ${!ordered_nodes[*]}; do
		local name=`convert-name $node`
		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
		local role=${ordered_nodes[$node]}
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
		add_str[$role]+="$name,"
		adding_count[$role]=$(( adding_count[$role]+1 ))
		cluster_nodes[$node]=$role		
	done

	# Prepare leaving nodes for removing, not exceeding the number of adding nodes
	declare -A remove_str=([slave]='' [tb]='')
	for node in ${!leaving_nodes[*]}; do
		local role=${cluster_nodes[$node]}
		if (( adding_count[$role]-- <= 0 )); then continue; fi
		local name=`convert-name $node`
		remove_str[$role]+="$name,"
		unset cluster_nodes[$node]
	done
	
	# Issue the cluster command for growing
	juju-log "ScaleIO cluster is being restored to $required_mode with adding slaves ${add_str[slave]} " \
		"tbs ${add_str[tb]} removing slaves ${remove_str[slave]} tbs ${remove_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': slave_names=>'${add_str[slave]}', tb_names=>'${add_str[tb]}', slave_names_to_replace=>'${remove_str[slave]}', tb_names_to_replace=>'${remove_str[tb]}' }"
	juju-log "ScaleIO cluster is successfully restored to $required_mode"

	update-cluster-ips
	leader-set ordered_nodes=
	leader-set cluster_nodes="`declare -p cluster_nodes`"
}

function grow-cluster {
	# Grow the Cluster
	mode_change=$(( (required_mode - current_mode) / 2 ))
	
	if [[ `order-nodes mode_change mode_change` == 1 ]]; then
		# Ordered required roles, leaving for now
		return 0
	fi
		# Prepare replacement nodes for adding
	declare -A add_str=([slave]='' [tb]='')
	for node in ${!ordered_nodes[*]}; do
		local name=`convert-name $node`
		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
		local role=${ordered_nodes[$node]}
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
		add_str[$role]+="$name,"
		cluster_nodes[$node]=$role	
	done

	# Issue the cluster command for growing
	juju-log "ScaleIO cluster is being grown to $required_mode - slaves: ${add_str[slave]}, tbs: ${add_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${add_str[slave]}', tb_names=>'${add_str[tb]}' }"
	juju-log "ScaleIO cluster is successfully grown to $required_mode"

	update-cluster-ips
	leader-set ordered_nodes=
	leader-set cluster_nodes="`declare -p cluster_nodes`"
}

function update-cluster-ips
{
	# The function should be called by leader only

	local internal_ips=''
	local management_ips=''
  	for node in ${!cluster_nodes[*]}; do
  		local role=${cluster_nodes[$node]}
  		if [[ $role == tb ]]; then continue; fi
  		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
  		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
  		internal_ips+="$internal_ip,"
  		management_ips+="$management_ip,"
	done  
	leader-set mdm_internal_ips=$internal_ips mdm_management_ips=$management_ips
	relation-set-all
}
