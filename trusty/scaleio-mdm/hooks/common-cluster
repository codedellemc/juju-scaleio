#!/bin/bash
if [ -z "$my_dir" ]; then my_dir="$(dirname "$0")"; fi
. "$my_dir/common"

scaleio_cluster_rids=(`relation-ids scaleio-cluster`)
if [[ -z ${scaleio_cluster_rids[*]+x} ]]; then exit 0; fi
scaleio_cluster_rid=${scaleio_cluster_rids[0]}
required_mode=`config-get cluster-mode`
current_mode=`leader-get cluster_mode`
eval `leader-get cluster_nodes`
eval `leader-get ordered_nodes`
declare -A present_nodes=()
declare -A leaving_nodes=()
declare -A ready_nodes=()
declare -A required_count
declare -A current_count
declare -A leaving_count=([tb]=0 [manager]=0)
declare -A present_count=([tb]=0 [manager]=0 [none]=0)
required_count[tb]=$(( (required_mode-1)/2 ))
required_count[manager]=$(( (required_mode+1)/2))
current_count[tb]=$(( (current_mode-1)/2 ))
current_count[manager]=$(( (current_mode+1)/2))

function retrieve-cluster-info {
	# The function should be called in a scope of scaleio-cluster-relation-* hooks only

	# Looking up present nodes and recording their roles in present_nodes
	local nodes=(`relation-list -r $scaleio_cluster_rid` $JUJU_UNIT_NAME)
  	for node in ${nodes[*]}; do
  		# TODO: Most probably the check below isn't required
  		local role=`relation-get -r $scaleio_cluster_rid role $node`
		present_nodes[$node]=$role
		present_count[$role]=$(( present_count[$role]+1 ))
    done

	# Looking for absent nodes and recording their roles in leaving_nodes
	for node in ${!cluster_nodes[*]}; do
		if [ -z "${present_nodes[$node]+x}" ]; then
			local role=${cluster_nodes[$node]}
			leaving_nodes[$node]=$role
			leaving_count[$role]=$(( leaving_count[$role]+1 ))
		fi
	done
} 	

function adjust-cluster {
	# The function should be called in a scope of scaleio-cluster-relation-* hooks only
	
	if [[ -z ${scaleio_cluster_rid+x} ]]; then exit 0; fi
	
	retrieve-cluster-info

	# Adjust or restore cluster
	if (( required_mode < current_mode )); then
		reduce-cluster
	elif (( required_mode == current_mode && (leaving_count[manager] > 0 || leaving_count[tb] > 0) )); then
		restore-cluster
	elif (( required_mode > current_mode )); then
		grow-cluster
	fi
}

function order-status {
	# Check if we have enough ready nodes of required roles. Order and return if not
	declare -A additional_nodes_count=([manager]=$1 [tb]=$2)

	for node in ${!present_nodes[*]}; do
		if [ -n "${cluster_nodes[$node]+x}" ]; then continue; fi
		local role=${present_nodes[$node]}
		if (( additional_nodes_count[$role]-- > 0)); then
			ready_nodes[$node]=$role
		fi
	done
	# Check if requirements are satisfied
	if (( additional_nodes_count[manager] > 0 || additional_nodes_count[tb] > 0 )); then
		juju-log "ScaleIO MDM cluster, not enough required roles exist - need to order more"
		ready_nodes=()
	fi
}

function order-nodes {
	# Check if we have enough ready nodes of required roles. Order and return if not
	local additional_manager_count=$1
	local additional_tb_count=$2

	# Check if enough nodes of required roles exist
	order-status $additional_manager_count $additional_tb_count
	if [ -n "${ready_nodes[*]+x}" ] || [ -n "${ordered_nodes[*]+x}" ]; then return 0; fi

		# Order required roles
	declare -A ordered_nodes=()
	for node in ${!present_nodes[*]}; do
		if [ -n "${cluster_nodes[$node]+x}" ]; then continue; fi
		if (( additional_manager_count > 0 )); then
			ordered_nodes[$node]=manager
			additional_manager_count=$(( additional_manager_count-1 ))
		elif (( additional_tb_count > 0 )); then
			ordered_nodes[$node]=tb
			additional_tb_count=$(( additional_tb_count-1 ))
		fi
	done
		
	# Check if enough spares exists
	if (( additional_manager_count > 0 || additional_tb_count > 0 )); then
		juju-log "Not enough spare nodes exist - requested mode: $required_mode, current mode: $current_mode"
	else
		leader-set ordered_nodes="`declare -p ordered_nodes`"
	fi
}

function reduce-cluster {
	# Reduces the Cluster

	mode_change=$(( (current_mode - required_mode) / 2 ))
	
	# Resizing from 5 or 3 to 1 can be done half-nicely, we should wait for managers to depart and then remove the tiebreakers and switch to 1
	# Removing of all MDMs except one manager at the moment kills the cluster so we have to resort to having one tiebreaker left at least
	# In order to determine which manager will stay we need to wait for the rest of them to leave
	if (( required_mode == 1 && leaving_count[manager] < mode_change )); then
		juju-log "Reducing cluster to 1 is not done - waiting for managers to depart first"
		return 0
	fi

	# Resizing from 5 to 3 can be done nicely, waiting until specific nodes are removed explicitly
	if (( required_mode == 3 && (leaving_count[tb] == 0 || leaving_count[manager] == 0) )); then
		juju-log "Reducing cluster from 5 to 3 is not done - waiting for more nodes to depart first"
		return 0
	fi

	# Prepare leaving nodes for removing
	declare -A mode_change_count=([manager]=$mode_change [tb]=$mode_change)
	to_remove=()
	declare -A remove_str
	for node in ${!leaving_nodes[*]} ${!cluster_nodes[*]}; do
		local role=${cluster_nodes[$node]}
		local name=`convert-name $node`
		if [[ remove_str[$role] == *"$name,"* ]] || (( mode_change_count[$role]-- <= 0 )); then continue; fi
		to_remove+=($node)
		remove_str[$role]+="$name,"
	done
	
	# Issue the cluster command for reducing
	juju-log "ScaleIO cluster is being reduced to $required_mode - managers: ${remove_str[manager]}, tbs: ${remove_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${remove_str[manager]}', tb_names=>'${remove_str[tb]}', ensure=>'absent' }"
	for node in ${to_remove[*]}; do
		local name=`convert-name $node`
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ensure=>'absent' }"
		unset cluster_nodes[$node]
	done
	juju-log "ScaleIO cluster is successfully reduced to $required_mode"

	update-cluster-ips
	leader-set cluster_nodes="`declare -p cluster_nodes`" cluster_mode=$required_mode
}

function restore-cluster {
	# Restore the Cluster

	order-nodes ${leaving_count[manager]} ${leaving_count[tb]}
	if [ -z "${ready_nodes[*]+x}" ]; then return 0; fi

	# Ordered roles delivered, restoring the Cluster

	# Prepare replacement nodes for adding
	declare -A adding_count=([manager]=0 [tb]=0)
	declare -A add_str=([manager]='' [tb]='')
	for node in ${!ready_nodes[*]}; do
		local name=`convert-name $node`
		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
		local role=${ready_nodes[$node]}
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
		add_str[$role]+="$name,"
		adding_count[$role]=$(( adding_count[$role]+1 ))
		cluster_nodes[$node]=$role		
	done

	# Prepare leaving nodes for removing, not exceeding the number of adding nodes
	declare -A remove_str=([manager]='' [tb]='')
	for node in ${!leaving_nodes[*]}; do
		local role=${cluster_nodes[$node]}
		if (( adding_count[$role]-- <= 0 )); then continue; fi
		local name=`convert-name $node`
		remove_str[$role]+="$name,"
		unset cluster_nodes[$node]
	done
	
	# Issue the cluster command for growing
	juju-log "ScaleIO cluster is being restored to $required_mode with adding managers ${add_str[manager]} " \
		"tbs ${add_str[tb]} removing managers ${remove_str[manager]} tbs ${remove_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': slave_names=>'${add_str[manager]}', tb_names=>'${add_str[tb]}', slave_names_to_replace=>'${remove_str[manager]}', tb_names_to_replace=>'${remove_str[tb]}' }"
	juju-log "ScaleIO cluster is successfully restored to $required_mode"

	update-cluster-ips
	leader-set ordered_nodes=
	leader-set cluster_nodes="`declare -p cluster_nodes`"
}

function grow-cluster {
	# Grow the Cluster
	mode_change=$(( (required_mode - current_mode) / 2 ))
	
	order-nodes $mode_change $mode_change
	if [ -z "${ready_nodes[*]+x}" ]; then return 0; fi
		
	# Prepare replacement nodes for adding
	declare -A add_str=([manager]='' [tb]='')
	for node in ${!ready_nodes[*]}; do
		local name=`convert-name $node`
		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
		local role=${ready_nodes[$node]}
		cluster-cmd "scaleio::mdm { 'mdm $node': name=>'$name', ips=>'$internal_ip', role=>'$role', management_ips=>'$management_ip' }"
		add_str[$role]+="$name,"
		cluster_nodes[$node]=$role	
	done

	# Issue the cluster command for growing
	juju-log "ScaleIO cluster is being grown to $required_mode - managers: ${add_str[manager]}, tbs: ${add_str[tb]}"
	cluster-cmd "scaleio::cluster {'cluster': cluster_mode=>'$required_mode', slave_names=>'${add_str[manager]}', tb_names=>'${add_str[tb]}' }"
	juju-log "ScaleIO cluster is successfully grown to $required_mode"

	update-cluster-ips
	leader-set ordered_nodes=
	leader-set cluster_nodes="`declare -p cluster_nodes`" cluster_mode=$required_mode
}

function update-cluster-ips
{
	# The function should be called by leader only

	local internal_ips=''
	local management_ips=''
  	for node in ${!cluster_nodes[*]}; do
  		local role=${cluster_nodes[$node]}
  		if [[ $role == tb ]]; then continue; fi
  		local internal_ip=`relation-get -r $scaleio_cluster_rid internal_ip $node`
  		local management_ip=`relation-get -r $scaleio_cluster_rid management_ip $node`
  		internal_ips+="$internal_ip,"
  		management_ips+="$management_ip,"
	done  
	leader-set mdm_internal_ips=$internal_ips mdm_management_ips=$management_ips
	relation-set-all
}
